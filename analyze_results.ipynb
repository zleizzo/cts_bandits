{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "from experiment_with_t import *\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 335/335 [12:25<00:00,  2.23s/it]\n"
     ]
    }
   ],
   "source": [
    "torch.random.manual_seed(42)\n",
    "\n",
    "samples = []\n",
    "bdry_samples = []\n",
    "n = 1000\n",
    "for i in range(n):\n",
    "    samples.append(sample(K))\n",
    "    bdry_samples.append(sample(K, t=1.))\n",
    "\n",
    "\n",
    "best_loss = float('inf')\n",
    "for model_path in tqdm(os.listdir('models')):\n",
    "    PATH = f'models/{model_path}'\n",
    "    model = model_path.split(',')\n",
    "    if model[-1][-3:] != '.pt':\n",
    "        continue\n",
    "    else:\n",
    "        hl_size, reg, lr, batch_size, iters = model\n",
    "        hl_size = int(hl_size)\n",
    "        reg = float(reg)\n",
    "        lr = float(lr)\n",
    "        batch_size = int(batch_size)\n",
    "        iters = int(iters[:-3])\n",
    "\n",
    "        net = BigNet(K, hl_size)\n",
    "        net.load_state_dict(torch.load(PATH))\n",
    "\n",
    "        loss = 0.\n",
    "        bdry_loss = 0.\n",
    "        for state, bdry_state in zip(samples, bdry_samples):\n",
    "            t, s, q = state\n",
    "            _, bdry_s, bdry_q = bdry_state\n",
    "            loss += hjb_term(net, t, s, q, lam, p, K)\n",
    "            bdry_loss += hjb_bdry(net, s, q, p)\n",
    "        \n",
    "        total_loss = loss + bdry_loss\n",
    "        if total_loss < best_loss:\n",
    "            best_dict = {\n",
    "                'net':net,\n",
    "                'hl_size':hl_size,\n",
    "                'reg':reg,\n",
    "                'lr':lr,\n",
    "                'batch_size':batch_size,\n",
    "                'iters':iters,\n",
    "                'loss':loss/n,\n",
    "                'bdry_loss':bdry_loss/n,\n",
    "                'total_loss':total_loss/n\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'net': BigNet(\n",
       "   (fc1): Linear(in_features=9, out_features=60, bias=True)\n",
       "   (fc2): Linear(in_features=60, out_features=60, bias=True)\n",
       "   (fc3): Linear(in_features=60, out_features=1, bias=True)\n",
       " ),\n",
       " 'hl_size': 60,\n",
       " 'reg': 0.1,\n",
       " 'lr': 0.3,\n",
       " 'batch_size': 5,\n",
       " 'iters': 100000,\n",
       " 'loss': tensor(1.1951, grad_fn=<DivBackward0>),\n",
       " 'bdry_loss': tensor([0.], grad_fn=<DivBackward0>),\n",
       " 'total_loss': tensor([1.1951], grad_fn=<DivBackward0>)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_dict\n",
    "# Best results: {'net': BigNet(\n",
    "#    (fc1): Linear(in_features=9, out_features=60, bias=True)\n",
    "#    (fc2): Linear(in_features=60, out_features=60, bias=True)\n",
    "#    (fc3): Linear(in_features=60, out_features=1, bias=True)\n",
    "#  ),\n",
    "#  'hl_size': 60,\n",
    "#  'reg': 0.1,\n",
    "#  'lr': 0.3,\n",
    "#  'batch_size': 5,\n",
    "#  'iters': 100000,\n",
    "#  'loss': tensor(1.1946, grad_fn=<DivBackward0>),\n",
    "#  'bdry_loss': tensor([0.], grad_fn=<DivBackward0>),\n",
    "#  'total_loss': tensor([1.1946], grad_fn=<DivBackward0>)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hl_size = 60\n",
    "reg = 0.1\n",
    "lr = 0.3\n",
    "batch_size = 5\n",
    "iters = 100000\n",
    "PATH = f'models/{hl_size},{reg},{lr},{batch_size},{iters}.pt'\n",
    "net = BigNet(K, hl_size)\n",
    "net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = best_dict['net']\n",
    "n = 100\n",
    "reps = 10\n",
    "# rwds = run_policy(net, n, reps, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6253, 0.3445, 0.9178, 0.7326])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.86it/s]\n"
     ]
    }
   ],
   "source": [
    "mus = torch.rand(K)\n",
    "print(mus)\n",
    "rwds2 = run_policy_fixed_mu(net, n, reps, mus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2200, 0.4400, 0.5000, 0.3000, 0.1800, 0.5200, 0.3800, 0.3400, 0.2400,\n",
       "        0.3200])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rwds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3101)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(2 * mus - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2493, 0.2547, 0.2568, 0.2392], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t, s, q = sample(K)\n",
    "policy(net, t, s, q, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3440)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(rwds2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.random.manual_seed(42)\n",
    "\n",
    "samples = []\n",
    "bdry_samples = []\n",
    "n = 1000\n",
    "for i in range(n):\n",
    "    samples.append(sample(K))\n",
    "    bdry_samples.append(sample(K, t=1.))\n",
    "\n",
    "\n",
    "best_loss = float('inf')\n",
    "for model_path in tqdm(os.listdir('models')):\n",
    "    PATH = f'models/{model_path}'\n",
    "    model = model_path.split(',')\n",
    "    if model[-1][-3:] != '.pt':\n",
    "        continue\n",
    "    else:\n",
    "        hl_size, reg, lr, batch_size, iters = model\n",
    "        hl_size = int(hl_size)\n",
    "        reg = float(reg)\n",
    "        lr = float(lr)\n",
    "        batch_size = int(batch_size)\n",
    "        iters = int(iters[:-3])\n",
    "\n",
    "        if iters > 100000:\n",
    "            print(iters)\n",
    "            net = BigNet(K, hl_size)\n",
    "            net.load_state_dict(torch.load(PATH))\n",
    "\n",
    "            loss = 0.\n",
    "            bdry_loss = 0.\n",
    "            for state, bdry_state in zip(samples, bdry_samples):\n",
    "                t, s, q = state\n",
    "                _, bdry_s, bdry_q = bdry_state\n",
    "                loss += hjb_term(net, t, s, q, lam, p, K)\n",
    "                bdry_loss += hjb_bdry(net, s, q, p)\n",
    "            \n",
    "            total_loss = loss + bdry_loss\n",
    "            if total_loss < best_loss:\n",
    "                best_dict2 = {\n",
    "                    'net':net,\n",
    "                    'hl_size':hl_size,\n",
    "                    'reg':reg,\n",
    "                    'lr':lr,\n",
    "                    'batch_size':batch_size,\n",
    "                    'iters':iters,\n",
    "                    'loss':loss/n,\n",
    "                    'bdry_loss':bdry_loss/n,\n",
    "                    'total_loss':total_loss/n\n",
    "                }\n",
    "\n",
    "print(best_dict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'net': BigNet(\n",
       "   (fc1): Linear(in_features=9, out_features=60, bias=True)\n",
       "   (fc2): Linear(in_features=60, out_features=60, bias=True)\n",
       "   (fc3): Linear(in_features=60, out_features=1, bias=True)\n",
       " ),\n",
       " 'hl_size': 60,\n",
       " 'reg': 0.03,\n",
       " 'lr': 0.3,\n",
       " 'batch_size': 5,\n",
       " 'iters': 1000000,\n",
       " 'loss': tensor(1.1903, grad_fn=<DivBackward0>),\n",
       " 'bdry_loss': tensor([0.], grad_fn=<DivBackward0>),\n",
       " 'total_loss': tensor([1.1903], grad_fn=<DivBackward0>)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'net': BigNet(\n",
    "#    (fc1): Linear(in_features=9, out_features=60, bias=True)\n",
    "#    (fc2): Linear(in_features=60, out_features=60, bias=True)\n",
    "#    (fc3): Linear(in_features=60, out_features=1, bias=True)\n",
    "#  ),\n",
    "#  'hl_size': 60,\n",
    "#  'reg': 0.03,\n",
    "#  'lr': 0.3,\n",
    "#  'batch_size': 5,\n",
    "#  'iters': 1000000,\n",
    "#  'loss': tensor(1.1903, grad_fn=<DivBackward0>),\n",
    "#  'bdry_loss': tensor([0.], grad_fn=<DivBackward0>),\n",
    "#  'total_loss': tensor([1.1903], grad_fn=<DivBackward0>)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4141, 0.8813, 0.7742, 0.6505])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.39it/s]\n"
     ]
    }
   ],
   "source": [
    "net = best_dict2['net']\n",
    "n = 100\n",
    "reps = 10\n",
    "# rwds = run_policy(net, n, reps, K)\n",
    "mus = torch.rand(K)\n",
    "print(mus)\n",
    "rwds2 = run_policy_fixed_mu(net, n, reps, mus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5000, 0.4000, 0.4600, 0.3200, 0.4200, 0.4400, 0.2600, 0.2800, 0.3800,\n",
      "        0.5000])\n"
     ]
    }
   ],
   "source": [
    "print(rwds2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1718,  0.7626,  0.5484,  0.3009])\n"
     ]
    }
   ],
   "source": [
    "print(2 * mus - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3233])\n",
      "big! tensor([0.9842])\n",
      "big! tensor([0.7160])\n",
      "big! tensor([0.9071])\n",
      "big! tensor([0.5577])\n",
      "tensor([0.1629])\n",
      "big! tensor([0.5832])\n",
      "big! tensor([0.6821])\n",
      "big! tensor([0.6227])\n",
      "tensor([0.4694])\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    x = torch.rand(1)\n",
    "    if x < 0.5:\n",
    "        print(x)\n",
    "    else:\n",
    "        print(f'big! {x}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 1., 1.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.bernoulli(mus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs = torch.randn(4) + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "from experiment_with_t import *\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/500 [00:07<1:05:56,  7.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on iter 0: tensor([0.0004], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 101/500 [11:17<24:08,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on iter 100: tensor([3.3486e-06], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 201/500 [11:48<01:49,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on iter 200: tensor([3.3368e-06], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 301/500 [12:16<01:13,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on iter 300: tensor([3.3368e-06], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 401/500 [12:45<00:36,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on iter 400: tensor([3.3368e-06], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [13:13<00:00,  1.59s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BigNet(\n",
       "  (fc1): Linear(in_features=9, out_features=60, bias=True)\n",
       "  (fc2): Linear(in_features=60, out_features=60, bias=True)\n",
       "  (fc3): Linear(in_features=60, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = BigNet(K, hl_size=60)\n",
    "num_samples = 100\n",
    "train_lbfgs(net, num_samples, 500, 0.03, lam, p, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3065, 0.2471, 0.1774, 0.2690], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t, s, q = sample(K)\n",
    "policy(net, t, s, q, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiments for n=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:14<00:00,  1.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiments for n=1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:20<00:00, 14.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiments for n=10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [23:16<00:00, 139.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random: 0.062489598989486694\n",
      "epsilon-Greedy: 2.432475286970536\n",
      "UCB: 2.5187605460484823\n",
      "Ours: 0.0451511046787103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ns = [100, 1000, 10000]\n",
    "expts = 10\n",
    "reps = 10\n",
    "\n",
    "greedy_rwds = np.zeros((len(ns), expts, reps))\n",
    "ucb_rwds = np.zeros((len(ns), expts, reps))\n",
    "our_rwds = np.zeros((len(ns), expts, reps))\n",
    "random_rwds = np.zeros((len(ns), expts))\n",
    "\n",
    "\n",
    "for i, n in enumerate(ns):\n",
    "    print(f'Experiments for n={n}')\n",
    "    for j in tqdm(range(expts)):\n",
    "        # print(f'Start experiment {j + 1} (n = {n})')\n",
    "        mus = torch.rand(K)\n",
    "        random_rwds[i, j] = 2 * np.mean(mus.numpy()) - 1\n",
    "\n",
    "        # print('Run greedy')\n",
    "        greedy_rwds[i, j, :] = eps_greedy(n, reps, mus, 1.).numpy()\n",
    "        \n",
    "        # print('Run UCB')\n",
    "        ucb_rwds[i, j, :] = ucb(n, reps, mus).numpy()\n",
    "\n",
    "        # print('Run ours')\n",
    "        our_rwds[i, j, :] = run_policy_fixed_mu(net, n, reps, mus).numpy()\n",
    "\n",
    "print(f'Random: {np.mean(random_rwds)}')\n",
    "print(f'epsilon-Greedy: {np.mean(greedy_rwds)}')\n",
    "print(f'UCB: {np.mean(ucb_rwds)}')\n",
    "print(f'Ours: {np.mean(our_rwds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiments for n=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:15<00:00,  1.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiments for n=1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:42<00:00, 16.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random: 0.09856199324131013\n",
      "epsilon-Greedy: 2.4173818510770797\n",
      "UCB: 2.6026742637529967\n",
      "Ours: 0.11017007758840919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ns = [100, 1000]\n",
    "expts = 10\n",
    "reps = 10\n",
    "\n",
    "greedy_rwds_beta = np.zeros((len(ns), expts, reps))\n",
    "ucb_rwds_beta = np.zeros((len(ns), expts, reps))\n",
    "our_rwds_beta = np.zeros((len(ns), expts, reps))\n",
    "random_rwds_beta = np.zeros((len(ns), expts))\n",
    "\n",
    "\n",
    "for i, n in enumerate(ns):\n",
    "    print(f'Experiments for n={n}')\n",
    "    for j in tqdm(range(expts)):\n",
    "        # print(f'Start experiment {j + 1} (n = {n})')\n",
    "        mus = torch.rand(K)\n",
    "        random_rwds_beta[i, j] = 2 * np.mean(mus.numpy()) - 1\n",
    "\n",
    "        # print('Run greedy')\n",
    "        greedy_rwds_beta[i, j, :] = eps_greedy(n, reps, mus, 1.).numpy()\n",
    "        \n",
    "        # print('Run UCB')\n",
    "        ucb_rwds_beta[i, j, :] = ucb(n, reps, mus).numpy()\n",
    "\n",
    "        # print('Run ours')\n",
    "        our_rwds_beta[i, j, :] = run_policy_fixed_mu(net, n, reps, mus).numpy()\n",
    "\n",
    "print(f'Random: {np.mean(random_rwds_beta)}')\n",
    "print(f'epsilon-Greedy: {np.mean(greedy_rwds_beta)}')\n",
    "print(f'UCB: {np.mean(ucb_rwds_beta)}')\n",
    "print(f'Ours: {np.mean(our_rwds_beta)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "softmax() received an invalid combination of arguments - got (Tensor), but expected one of:\n * (Tensor input, int dim, torch.dtype dtype)\n * (Tensor input, name dim, *, torch.dtype dtype)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-3307a07cbab7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPINN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mtrained_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_lbfgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.03\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/repos/cts_bandits/experiment_with_t.py\u001b[0m in \u001b[0;36mtrain_lbfgs\u001b[0;34m(net, num_samples, iters, reg, lam, p, K)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Loss on iter {i}: {closure()}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/optim/lbfgs.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;31m# evaluate initial f(x) and df/dx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m         \u001b[0morig_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0mcurrent_evals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/cts_bandits/experiment_with_t.py\u001b[0m in \u001b[0;36mclosure\u001b[0;34m()\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_bdry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_bdry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msx_bdry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqx_bdry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mhjb_term\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m             \u001b[0mbdry_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mhjb_bdry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_bdry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_bdry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/cts_bandits/experiment_with_t.py\u001b[0m in \u001b[0;36mhjb_term\u001b[0;34m(net, t, s, q, lam, p, K)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mgrad_V\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_grad_V\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0mlogsumexp_terms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_logsumexp_terms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/cts_bandits/experiment_with_t.py\u001b[0m in \u001b[0;36mcompute_grad_V\u001b[0;34m(net, state)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_grad_V\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0mgrad_V\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_V\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-3307a07cbab7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: softmax() received an invalid combination of arguments - got (Tensor), but expected one of:\n * (Tensor input, int dim, torch.dtype dtype)\n * (Tensor input, name dim, *, torch.dtype dtype)\n"
     ]
    }
   ],
   "source": [
    "class PINN(nn.Module):\n",
    "    def __init__(self, K):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(2 * K + 1, 100)\n",
    "        self.fc2 = nn.Linear(100, 100)\n",
    "        self.fc3 = nn.Linear(100, 100)\n",
    "        self.fc4 = nn.Linear(100, 100)\n",
    "        self.fc5 = nn.Linear(100, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        x = torch.tanh(self.fc3(x))\n",
    "        x = torch.tanh(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        return x\n",
    "\n",
    "net = PINN(K)\n",
    "num_samples = 2000\n",
    "trained_net = train_lbfgs(net, num_samples, 500, 0.03, lam, p, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(trained_net.state_dict(), 'lbfgs_trained.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiments for n=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:34<00:00,  3.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiments for n=1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [06:37<00:00, 39.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random: -0.015937143564224245\n",
      "epsilon-Greedy: 2.0141468712780624\n",
      "UCB: 2.297837796732783\n",
      "Ours: -0.00244005830027163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ns = [100, 1000]\n",
    "expts = 10\n",
    "reps = 10\n",
    "\n",
    "greedy_rwds_beta = np.zeros((len(ns), expts, reps))\n",
    "ucb_rwds_beta = np.zeros((len(ns), expts, reps))\n",
    "our_rwds_beta = np.zeros((len(ns), expts, reps))\n",
    "random_rwds_beta = np.zeros((len(ns), expts))\n",
    "\n",
    "\n",
    "for i, n in enumerate(ns):\n",
    "    print(f'Experiments for n={n}')\n",
    "    for j in tqdm(range(expts)):\n",
    "        # print(f'Start experiment {j + 1} (n = {n})')\n",
    "        mus = torch.rand(K)\n",
    "        random_rwds_beta[i, j] = 2 * np.mean(mus.numpy()) - 1\n",
    "\n",
    "        # print('Run greedy')\n",
    "        greedy_rwds_beta[i, j, :] = eps_greedy(n, reps, mus, 1.).numpy()\n",
    "        \n",
    "        # print('Run UCB')\n",
    "        ucb_rwds_beta[i, j, :] = ucb(n, reps, mus).numpy()\n",
    "\n",
    "        # print('Run ours')\n",
    "        our_rwds_beta[i, j, :] = run_policy_fixed_mu(trained_net, n, reps, mus).numpy()\n",
    "\n",
    "print(f'Random: {np.mean(random_rwds_beta)}')\n",
    "print(f'epsilon-Greedy: {np.mean(greedy_rwds_beta)}')\n",
    "print(f'UCB: {np.mean(ucb_rwds_beta)}')\n",
    "print(f'Ours: {np.mean(our_rwds_beta)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
